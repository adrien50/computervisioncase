{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normalize, Center, and Standardize Image Pixels in Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPp6NoMbO5dHr7JqR2kYHVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrien50/computervisioncase/blob/main/Normalize%2C_Center%2C_and_Standardize_Image_Pixels_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbLy6B4-Vf9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMo-OT_oVhyO"
      },
      "source": [
        "###MNIST Handwritten Image Classification Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwIph7MHVnrC"
      },
      "source": [
        "Before we dive into the usage of the ImageDataGenerator class for preparing image data, we must select an image dataset on which to test the generator.\r\n",
        "\r\n",
        "The MNIST problem, is an image classification problem comprised of 70,000 images of handwritten digits.\r\n",
        "\r\n",
        "The goal of the problem is to classify a given image of a handwritten digit as an integer from 0 to 9. As such, it is a multiclass image classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8enSaIdDV0sT",
        "outputId": "8231b8f5-5185-4d9e-c5df-fa6fed3c4cc2"
      },
      "source": [
        "# load and summarize the MNIST dataset\r\n",
        "from keras.datasets import mnist\r\n",
        "# load dataset\r\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\r\n",
        "# summarize dataset shape\r\n",
        "print('Train', train_images.shape, train_labels.shape)\r\n",
        "print('Test', (test_images.shape, test_labels.shape))\r\n",
        "# summarize pixel values\r\n",
        "print('Train', train_images.min(), train_images.max(), train_images.mean(), train_images.std())\r\n",
        "print('Test', test_images.min(), test_images.max(), test_images.mean(), test_images.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train (60000, 28, 28) (60000,)\n",
            "Test ((10000, 28, 28), (10000,))\n",
            "Train 0 255 33.318421449829934 78.56748998339798\n",
            "Test 0 255 33.791224489795916 79.17246322228644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQnytN8zWDcY"
      },
      "source": [
        "Running the example first loads the dataset into memory. Then the shape of the train and test datasets is reported.\r\n",
        "\r\n",
        "We can see that all images are 28 by 28 pixels with a single channel for black-and-white images. There are 60,000 images for the training dataset and 10,000 for the test dataset.\r\n",
        "\r\n",
        "We can also see that pixel values are integer values between 0 and 255 and that the mean and standard deviation of the pixel values are similar between the two datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meoNrlTlWogi"
      },
      "source": [
        "####ImageDataGenerator Class for Pixel Scaling\r\n",
        "\r\n",
        "The ImageDataGenerator class in Keras provides a suite of techniques for scaling pixel values in your image dataset prior to modeling.\r\n",
        "\r\n",
        "The class will wrap your image dataset, then when requested, it will return images in batches to the algorithm during training, validation, or evaluation and apply the scaling operations just-in-time. This provides an efficient and convenient approach to scaling image data when modeling with neural networks.\r\n",
        "\r\n",
        "The usage of the ImageDataGenerator class is as follows.\r\n",
        "\r\n",
        "1. Load your dataset.\r\n",
        "2. Configure the ImageDataGenerator (e.g. construct an instance).\r\n",
        "3. Calculate image statistics (e.g. call the fit() function).\r\n",
        "4. Use the generator to fit the model (e.g. pass the instance to the fit_generator() function).\r\n",
        "5. Use the generator to evaluate the model (e.g. pass the instance to the evaluate_generator() function)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqm5t7J_YTck"
      },
      "source": [
        "###How to Normalize Images With ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLnyVNTjV5Vm",
        "outputId": "3423a197-aa65-4023-d841-0ec5d7d21688"
      },
      "source": [
        "# example of using ImageDataGenerator to normalize images\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# load dataset\r\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\r\n",
        "# reshape dataset to have a single channel\r\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\r\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\r\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\r\n",
        "# one hot encode target values\r\n",
        "trainY = to_categorical(trainY)\r\n",
        "testY = to_categorical(testY)\r\n",
        "# confirm scale of pixels\r\n",
        "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\r\n",
        "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\r\n",
        "# create generator (1.0/255.0 = 0.003921568627451)\r\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\r\n",
        "# prepare an iterators to scale images\r\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\r\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\r\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\r\n",
        "# confirm the scaling works\r\n",
        "batchX, batchy = train_iterator.next()\r\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(64, activation='relu'))\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "# compile model\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "# fit model with generator\r\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\r\n",
        "# evaluate model\r\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\r\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train min=0.000, max=255.000\n",
            "Test min=0.000, max=255.000\n",
            "Batches train=938, test=157\n",
            "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 43s 45ms/step - loss: 0.3809 - accuracy: 0.8858\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0567 - accuracy: 0.9826\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0390 - accuracy: 0.9877\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 43s 45ms/step - loss: 0.0292 - accuracy: 0.9912\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0200 - accuracy: 0.9938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUPNVqTOY-f9"
      },
      "source": [
        "###How to Center Images With ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRgqPQ5QZB-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db97dbf5-edbf-4888-8b6c-41391a07faad"
      },
      "source": [
        "# example of centering a image dataset\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# load dataset\r\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\r\n",
        "# reshape dataset to have a single channel\r\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\r\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\r\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\r\n",
        "# report per-image mean\r\n",
        "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\r\n",
        "# create generator that centers pixel values\r\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\r\n",
        "# calculate the mean on the training dataset\r\n",
        "datagen.fit(trainX)\r\n",
        "print('Data Generator Mean: %.3f' % datagen.mean)\r\n",
        "# demonstrate effect on a single batch of samples\r\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=64)\r\n",
        "# get a batch\r\n",
        "batchX, batchy = iterator.next()\r\n",
        "# mean pixel value in the batch\r\n",
        "print(batchX.shape, batchX.mean())\r\n",
        "# demonstrate effect on entire training dataset\r\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\r\n",
        "# get a batch\r\n",
        "batchX, batchy = iterator.next()\r\n",
        "# mean pixel value in the batch\r\n",
        "print(batchX.shape, batchX.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Means train=33.318, test=33.791\n",
            "Data Generator Mean: 33.318\n",
            "(64, 28, 28, 1) 0.14109448\n",
            "(60000, 28, 28, 1) -1.9512918e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFXHzh76eyMo"
      },
      "source": [
        "Running the example first reports the mean pixel value for the train and test datasets.\r\n",
        "\r\n",
        "The MNIST dataset only has a single channel because the images are black and white (grayscale), but if the images were color, the mean pixel values would be calculated across all channels in all images in the training dataset, i.e. there would not be a separate mean value for each channel.\r\n",
        "\r\n",
        "The ImageDataGenerator is fit on the training dataset and we can confirm that the mean pixel value matches our own manual calculation.\r\n",
        "\r\n",
        "A single batch of centered images is retrieved and we can confirm that the mean pixel value is a small-ish value close to zero. The test is repeated using the entire training dataset as a the batch size, and in this case, the mean pixel value for the scaled dataset is a number very close to zero, confirming that centering is having the desired effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_yXi4snfKDO"
      },
      "source": [
        "The complete example with feature-wise centering is listed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQphWb-meyvf",
        "outputId": "a4766e25-be11-4001-8ff9-51cb9959441c"
      },
      "source": [
        "# example of using ImageDataGenerator to center images\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# load dataset\r\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\r\n",
        "# reshape dataset to have a single channel\r\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\r\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\r\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\r\n",
        "# one hot encode target values\r\n",
        "trainY = to_categorical(trainY)\r\n",
        "testY = to_categorical(testY)\r\n",
        "# create generator to center images\r\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\r\n",
        "# calculate mean on training dataset\r\n",
        "datagen.fit(trainX)\r\n",
        "# prepare an iterators to scale images\r\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\r\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\r\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(64, activation='relu'))\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "# compile model\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "# fit model with generator\r\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\r\n",
        "# evaluate model\r\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\r\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 42s 45ms/step - loss: 1.8016 - accuracy: 0.7897\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0863 - accuracy: 0.9736\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 42s 44ms/step - loss: 0.0507 - accuracy: 0.9846\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0411 - accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 43s 46ms/step - loss: 0.0394 - accuracy: 0.9879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ns2JYqEfPKN"
      },
      "source": [
        "###How to Standardize Image With ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFrBEcCkfrZO"
      },
      "source": [
        "\r\n",
        "Standardization is a data scaling technique that assumes that the distribution of the data is Gaussian and shifts the distribution of the data to have a mean of zero and a standard deviation of one.\r\n",
        "\r\n",
        "Data with this distribution is referred to as a standard Gaussian. It can be beneficial when training neural networks as the dataset sums to zero and the inputs are small values in the rough range of about -3.0 to 3.0 (e.g. 99.7 of the values will fall within three standard deviations of the mean).\r\n",
        "\r\n",
        "Standardization of images is achieved by subtracting the mean pixel value and dividing the result by the standard deviation of the pixel values.\r\n",
        "\r\n",
        "The mean and standard deviation statistics can be calculated on the training dataset, and as discussed in the previous section, Keras refers to this as feature-wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw2AqfuGfQ7Y",
        "outputId": "f5c64b89-5544-4bb6-97a8-23a8cbec5803"
      },
      "source": [
        "# example of standardizing a image dataset\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# load dataset\r\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\r\n",
        "# reshape dataset to have a single channel\r\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\r\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\r\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\r\n",
        "# report pixel means and standard deviations\r\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\r\n",
        "# create generator that centers pixel values\r\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\r\n",
        "# calculate the mean on the training dataset\r\n",
        "datagen.fit(trainX)\r\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\r\n",
        "# demonstrate effect on a single batch of samples\r\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=64)\r\n",
        "# get a batch\r\n",
        "batchX, batchy = iterator.next()\r\n",
        "# pixel stats in the batch\r\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\r\n",
        "# demonstrate effect on entire training dataset\r\n",
        "iterator = datagen.flow(trainX, trainy, batch_size=len(trainX), shuffle=False)\r\n",
        "# get a batch\r\n",
        "batchX, batchy = iterator.next()\r\n",
        "# pixel stats in the batch\r\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
            "Data Generator mean=33.318, std=78.567\n",
            "(64, 28, 28, 1) 0.0066464213 1.0060332\n",
            "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6pe7j4ogd-P"
      },
      "source": [
        "Running the example first reports the mean and standard deviation of pixel values in the train and test datasets.\r\n",
        "\r\n",
        "The data generator is then configured for feature-wise standardization and the statistics are calculated on the training dataset, matching what we would expect when the statistics are calculated manually.\r\n",
        "\r\n",
        "A single batch of 64 standardized images is then retrieved and we can confirm that the mean and standard deviation of this small sample is close to the expected standard Gaussian.\r\n",
        "\r\n",
        "The test is then repeated on the entire training dataset and we can confirm that the mean is indeed a very small value close to 0.0 and the standard deviation is a value very close to 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXz2FAHSgzY_",
        "outputId": "b18579f4-2bc6-4035-f455-c47adb892907"
      },
      "source": [
        "# example of using ImageDataGenerator to standardize images\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2D\r\n",
        "from keras.layers import MaxPooling2D\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# load dataset\r\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\r\n",
        "# reshape dataset to have a single channel\r\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\r\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\r\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\r\n",
        "# one hot encode target values\r\n",
        "trainY = to_categorical(trainY)\r\n",
        "testY = to_categorical(testY)\r\n",
        "# create generator to standardize images\r\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\r\n",
        "# calculate mean on training dataset\r\n",
        "datagen.fit(trainX)\r\n",
        "# prepare an iterators to scale images\r\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\r\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\r\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D((2, 2)))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(64, activation='relu'))\r\n",
        "model.add(Dense(10, activation='softmax'))\r\n",
        "# compile model\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "# fit model with generator\r\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\r\n",
        "# evaluate model\r\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\r\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 43s 45ms/step - loss: 0.3455 - accuracy: 0.8960\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0490 - accuracy: 0.9853\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0338 - accuracy: 0.9889\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0243 - accuracy: 0.9926\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 42s 45ms/step - loss: 0.0173 - accuracy: 0.9947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qE4MFrPhnwk"
      },
      "source": [
        "Keras Image Processing API\r\n",
        "\r\n",
        "The Keras deep learning library provides utilities for working with image data.\r\n",
        "\r\n",
        "The main API is the ImageDataGenerator class that combines data loading, preparation, and augmentation.\r\n",
        "\r\n",
        "We will not cover the ImageDataGenerator class in this tutorial. Instead, we will take a closer look at a few less-documented or undocumented functions that may be useful when working with image data and modeling with the Keras API.\r\n",
        "\r\n",
        "Specifically, Keras provides functions for loading, converting, and saving image data. The functions are in the utils.py function and exposed via the image.py module.\r\n",
        "\r\n",
        "These functions can be useful convenience functions when getting started on a new deep learning computer vision project or when you need to inspect specific images.\r\n",
        "\r\n",
        "Some of these functions are demonstrated when working with pre-trained models in the Applications section of the API documentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v79WFJulhuAf"
      },
      "source": [
        "### How to Load an Image with Keras\r\n",
        "\r\n",
        "Keras provides the load_img() function for loading an image from file as a PIL image object.\r\n",
        "\r\n",
        "The example below loads the Bondi Beach photograph from file as a PIL image and reports details about the loaded image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOPevYf9h6df"
      },
      "source": [
        "# example of loading an image with the Keras API\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "# load the image\r\n",
        "img = load_img('bondi_beach.jpg')\r\n",
        "# report details about the image\r\n",
        "print(type(img))\r\n",
        "print(img.format)\r\n",
        "print(img.mode)\r\n",
        "print(img.size)\r\n",
        "# show the image\r\n",
        "img.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-TAUbeMiCQc"
      },
      "source": [
        "###How to Convert an Image With Keras\r\n",
        "Keras provides the img_to_array() function for converting a loaded image in PIL format into a NumPy array for use with deep learning models.\r\n",
        "\r\n",
        "The API also provides the array_to_img() function that can be used for converting a NumPy array of pixel data into a PIL image. This can be useful if the pixel data is modified while the image is in array format and can then be saved or viewed.\r\n",
        "\r\n",
        "The example below loads the test image, converts it to a NumPy array, and then converts it back into a PIL image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjSSVwmkiI9I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXsZ6Z8siI_s"
      },
      "source": [
        "# example of converting an image with the Keras API\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "from keras.preprocessing.image import array_to_img\r\n",
        "# load the image\r\n",
        "img = load_img('bondi_beach.jpg')\r\n",
        "print(type(img))\r\n",
        "# convert to numpy array\r\n",
        "img_array = img_to_array(img)\r\n",
        "print(img_array.dtype)\r\n",
        "print(img_array.shape)\r\n",
        "# convert back to image\r\n",
        "img_pil = array_to_img(img_array)\r\n",
        "print(type(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIxZNt1Xi3GB"
      },
      "source": [
        "Running the example first loads the photograph in PIL format, then converts the image to a NumPy array and reports the data type and shape.\r\n",
        "\r\n",
        "We can see that the pixel values are converted from unsigned integers to 32-bit floating point values, and in this case, converted to the array format [height, width, channels]. Finally, the image is converted back into PIL format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ4cPQGJi7GL"
      },
      "source": [
        "###How to Save Image With Keras\r\n",
        "The Keras API also provides the save_img() function to save an image to file.\r\n",
        "\r\n",
        "The function takes the path to save the image, and the image data in NumPy array format. The file format is inferred from the filename, but can also be specified via the ‘file_format‘ argument.\r\n",
        "\r\n",
        "This can be useful if you have manipulated image pixel data, such as scaling, and wish to save the image for later use.\r\n",
        "\r\n",
        "The example below loads the photograph image in grayscale format, converts it to a NumPy array, and saves it to a new file name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bTPCAVfjASg"
      },
      "source": [
        "# example of saving an image with the Keras API\r\n",
        "from keras.preprocessing.image import load_img\r\n",
        "from keras.preprocessing.image import save_img\r\n",
        "from keras.preprocessing.image import img_to_array\r\n",
        "# load image as as grayscale\r\n",
        "img = load_img('bondi_beach.jpg', grayscale=True)\r\n",
        "# convert image to a numpy array\r\n",
        "img_array = img_to_array(img)\r\n",
        "# save the image with a new filename\r\n",
        "save_img('bondi_beach_grayscale.jpg', img_array)\r\n",
        "# load the image to confirm it was saved correctly\r\n",
        "img = load_img('bondi_beach_grayscale.jpg')\r\n",
        "print(type(img))\r\n",
        "print(img.format)\r\n",
        "print(img.mode)\r\n",
        "print(img.size)\r\n",
        "img.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4jakVNukIv5"
      },
      "source": [
        "Summary\r\n",
        "\r\n",
        "In this tutorial, you discovered how to use the basic image handling functions provided by the Keras API.\r\n",
        "\r\n",
        "Specifically, you learned:\r\n",
        "\r\n",
        "How to load and display an image using the Keras API.\r\n",
        "How to convert a loaded image to a NumPy array and back to PIL format using the Keras API.\r\n",
        "How to convert a loaded image to grayscale and save it to a new file using the Keras API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MxPC9engb8X"
      },
      "source": [
        ""
      ]
    }
  ]
}